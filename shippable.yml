# Language setting http://docs.shippable.com/ci/languages/node/
language: node_js

# Integrations are used to connect external resources to CI
# http://docs.shippable.com/integrations/overview/
integrations:
  # adding JFrog artifactory integration so that credentials are available to CI Job
  # http://docs.shippable.com/platform/integration/jfrog-artifactoryKey/#jfrog-artifactory-integration
  hub:
    - integrationName: drship_dockerregistry
      type: dockerRegistryLogin

# use this to control what branches get built.
# http://docs.shippable.com/ci/advancedOptions/branches/
branches:
  only:
    - master

# using pre-defined build variables
# full list http://docs.shippable.com/ci/advancedOptions/environmentVariables/
env:
  global:
    - TEST_RESULTS_DIR=$SHIPPABLE_REPO_DIR/shippable/testresults
    - CODE_COVERAGE_DIR=$SHIPPABLE_REPO_DIR/shippable/codecoverage
    - TESTS_LOC_DIR=$SHIPPABLE_REPO_DIR/tests
    - MOD_LOC=$SHIPPABLE_REPO_DIR/node_modules/.bin/
    - DOCKER_REPO="node_app_jfrog"
    - DOCKER_ACC=ambarc-node-app-jfrog.jfrog.io # {account name}
    - SHIP_IMG_RES=$DOCKER_REPO"_img_jf"

build:

  # http://docs.shippable.com/ci/shippableyml/#ci
  ci:
    # npm mirrors can sometimes be flacky, better to use shippable_retry
    # http://docs.shippable.com/ci/advancedOptions/retry/
    - shipctl retry "npm install"
    - mkdir -p $TEST_RESULTS_DIR && mkdir -p $CODE_COVERAGE_DIR
    - pushd $TESTS_LOC_DIR
    - $MOD_LOC/mocha --recursive "$TESTS_LOC_DIR/**/*.spec.js" -R mocha-junit-reporter --reporter-options mochaFile=$TEST_RESULTS_DIR/testresults.xml
    - $MOD_LOC/istanbul --include-all-sources cover -root "$SHIPPABLE_REPO_DIR/routes" $SHIPPABLE_REPO_DIR/node_modules/mocha/bin/_mocha -- -R spec-xunit-file --recursive "$TESTS_LOC_DIR/**/*.spec.js"
    - $MOD_LOC/istanbul report cobertura --dir $CODE_COVERAGE_DIR
    - popd

  # http://docs.shippable.com/ci/shippableyml/#post_ci
  post_ci:
    - docker build -t $DOCKER_ACC/$DOCKER_REPO:$BRANCH.$BUILD_NUMBER .
    - docker push $DOCKER_ACC/$DOCKER_REPO:$BRANCH.$BUILD_NUMBER

  #this will be ignored if you are not using Assembly Lines to trigger another job after ci
  on_success:
    - shipctl put_resource_state $SHIP_IMG_RES versionName $BRANCH.$BUILD_NUMBER

## OPTIONAL : In case you want to use this image in CD Assembly Lines
resources:
  - name: node_app_jfrog_img_jf
    type: image
    integration: drship_dockerregistry # replace with your integration name
    versionTemplate:
      sourceName: "ambarc-node-app-jfrog.jfrog.io/node_app_jfrog" # replace with your Hub URL
      isPull: false
      versionName: latest

# REPO of kube configs
  - name: node_app_jfrog_config_repo
    type: gitRepo
    integration: "drship_github"
    versionTemplate:
      sourceName: "ambarish2012/node_app_jfrog"
      branch: master

# kubernetes CLI Config
  - name: node_app_jfrog_kube_cli
    type: cliConfig
    integration: "drship_kube"

  - name: node_app_jfrog_dr
    type: integration
    # replace drship_dockerregistry with your Docker registry integration name
    integration: drship_dockerregistry

jobs:
  - name: node_app_jfrog_runCI
    type: runCI
    dependencyMode: strict
    triggerMode: parallel
    steps:
      - OUT: node_app_jfrog_img_jf
    flags:
      - node_app_jfrog

  - name: create_image_pull_secret_jfrog
    type: runSh
    steps:
      - IN: node_app_jfrog_kube_cli
      - IN: node_app_jfrog_dr
      - TASK:
          script:
            # Delete and create the secret
            - kubectl delete secret private-registry-key 2>/dev/null || echo "secret does not exist"
            - kubectl create secret docker-registry private-registry-key --docker-username="$NODE_APP_JFROG_DR_INTEGRATION_USERNAME" --docker-password="$NODE_APP_JFROG_DR_INTEGRATION_PASSWORD" --docker-email="$NODE_APP_JFROG_DR_INTEGRATION_EMAIL" --docker-server="$NODE_APP_JFROG_DR_INTEGRATION_URL"/

  - name: deploy_app_kctl_kube
    type: runSh
    dependencyMode: strict
    steps:
      - IN: node_app_jfrog_img_jf # defined here https://github.com/devops-recipes/node_app/blob/master/shippable.yml
      - IN: node_app_jfrog_kube_cli
        switch: off
      - IN: node_app_jfrog_config_repo
        switch: off
      - TASK:
          name: deploy_jfrog_app
          runtime:
            options:
              env:
                - APP_LABEL: "kctl-jfrog-app"
          script:
            - pushd $(shipctl get_resource_state "node_app_jfrog_config_repo")
            - cd specs
            - export APP_IMG=$(shipctl get_resource_version_key node_app_jfrog_img_jf sourceName)
            - export APP_TAG=$(shipctl get_resource_version_name node_app_jfrog_img_jf)
            - shipctl replace appDeploy.yml appSvc.yml
            - kubectl delete  -f ./appDeploy.yml 2>/dev/null || echo ""
            - kubectl delete -f ./appSvc.yml  2>/dev/null || echo ""
            - kubectl create -o json -f ./appDeploy.yml >> kube_output.json
            - kubectl create -o json -f ./appSvc.yml >> kube_output.json
            - cat kube_output.json
            - popd
    flags:
      - cd
      - kctl
      - jfrog
